{
    "nbformat_minor": 1,
    "cells": [
        {
            "source": "<table style=\"border: none\" align=\"left\">\n   <tr style=\"border: none\">\n      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Build, Save and Deploy a Model to IBM Watson Machine Learning (WML)</b></th>\n      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n   </tr>\n</table>",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "\nThis notebook walks you through these steps:\n- Build a Spark ML model to predict customer churn\n- Save the model in the WML repository\n- Create a Deployment in WML\n- Invoke the deployed model with a REST API call to test it",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "### Step 1: Download the customer churn data",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Run once to install the wget package\n#!pip install wget",
            "cell_type": "code",
            "execution_count": 1,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "import wget\nurl_churn='https://raw.githubusercontent.com/yfphoon/dsx_demo/master/data/customer_churn/churn.csv'\nurl_customer='https://raw.githubusercontent.com/yfphoon/dsx_demo/master/data/customer_churn/customer.csv'\n\n#remove existing files before downloading\n!rm -f churn.csv\n!rm -f customer.csv\n\nchurnFilename=wget.download(url_churn)\ncustomerFilename=wget.download(url_customer)\n\n!ls -l churn.csv\n!ls -l customer.csv",
            "cell_type": "code",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "-rw------- 1 s3b2-c7634938ff52ab-a5f39cf201a0 users 20079 Apr 30 13:50 churn.csv\n-rw------- 1 s3b2-c7634938ff52ab-a5f39cf201a0 users 279541 Apr 30 13:50 customer.csv\n"
                }
            ],
            "metadata": {}
        },
        {
            "source": "### Step 2: Create DataFrames with files",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n\nchurn= spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(\"churn.csv\")\n\ncustomer = spark.read\\\n    .format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\")\\\n    .option(\"header\", \"true\")\\\n    .option(\"inferSchema\", \"true\")\\\n    .load(\"customer.csv\")",
            "cell_type": "code",
            "execution_count": 3,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "### Step 3: Merge Files",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "data=customer.join(churn,customer['ID']==churn['ID']).select(customer['*'],churn['CHURN'])",
            "cell_type": "code",
            "execution_count": 4,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "### Step 4: Rename some columns\nThis step is to remove spaces from columns names",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "data = data.withColumnRenamed(\"Est Income\", \"EstIncome\").withColumnRenamed(\"Car Owner\",\"CarOwner\")\ndata.toPandas().head()",
            "cell_type": "code",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Gender</th>\n      <th>Status</th>\n      <th>Children</th>\n      <th>EstIncome</th>\n      <th>CarOwner</th>\n      <th>Age</th>\n      <th>LongDistance</th>\n      <th>International</th>\n      <th>Local</th>\n      <th>Dropped</th>\n      <th>Paymethod</th>\n      <th>LocalBilltype</th>\n      <th>LongDistanceBilltype</th>\n      <th>Usage</th>\n      <th>RatePlan</th>\n      <th>CHURN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>F</td>\n      <td>S</td>\n      <td>1</td>\n      <td>38000.00</td>\n      <td>N</td>\n      <td>24.393333</td>\n      <td>23.56</td>\n      <td>0</td>\n      <td>206.08</td>\n      <td>0</td>\n      <td>CC</td>\n      <td>Budget</td>\n      <td>Intnl_discount</td>\n      <td>229.64</td>\n      <td>3</td>\n      <td>T</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>M</td>\n      <td>M</td>\n      <td>2</td>\n      <td>29616.00</td>\n      <td>N</td>\n      <td>49.426667</td>\n      <td>29.78</td>\n      <td>0</td>\n      <td>45.50</td>\n      <td>0</td>\n      <td>CH</td>\n      <td>FreeLocal</td>\n      <td>Standard</td>\n      <td>75.29</td>\n      <td>2</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>M</td>\n      <td>M</td>\n      <td>0</td>\n      <td>19732.80</td>\n      <td>N</td>\n      <td>50.673333</td>\n      <td>24.81</td>\n      <td>0</td>\n      <td>22.44</td>\n      <td>0</td>\n      <td>CC</td>\n      <td>FreeLocal</td>\n      <td>Standard</td>\n      <td>47.25</td>\n      <td>3</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>M</td>\n      <td>S</td>\n      <td>2</td>\n      <td>96.33</td>\n      <td>N</td>\n      <td>56.473333</td>\n      <td>26.13</td>\n      <td>0</td>\n      <td>32.88</td>\n      <td>1</td>\n      <td>CC</td>\n      <td>Budget</td>\n      <td>Standard</td>\n      <td>59.01</td>\n      <td>1</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14</td>\n      <td>F</td>\n      <td>M</td>\n      <td>2</td>\n      <td>52004.80</td>\n      <td>N</td>\n      <td>25.140000</td>\n      <td>5.03</td>\n      <td>0</td>\n      <td>23.11</td>\n      <td>0</td>\n      <td>CH</td>\n      <td>Budget</td>\n      <td>Intnl_discount</td>\n      <td>28.14</td>\n      <td>1</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   ID Gender Status  Children  EstIncome CarOwner        Age  LongDistance  \\\n0   1      F      S         1   38000.00        N  24.393333         23.56   \n1   6      M      M         2   29616.00        N  49.426667         29.78   \n2   8      M      M         0   19732.80        N  50.673333         24.81   \n3  11      M      S         2      96.33        N  56.473333         26.13   \n4  14      F      M         2   52004.80        N  25.140000          5.03   \n\n   International   Local  Dropped Paymethod LocalBilltype  \\\n0              0  206.08        0        CC        Budget   \n1              0   45.50        0        CH     FreeLocal   \n2              0   22.44        0        CC     FreeLocal   \n3              0   32.88        1        CC        Budget   \n4              0   23.11        0        CH        Budget   \n\n  LongDistanceBilltype   Usage  RatePlan CHURN  \n0       Intnl_discount  229.64         3     T  \n1             Standard   75.29         2     F  \n2             Standard   47.25         3     F  \n3             Standard   59.01         1     F  \n4       Intnl_discount   28.14         1     F  "
                    },
                    "execution_count": 5
                }
            ],
            "metadata": {}
        },
        {
            "source": "### Step 5: Build the Spark pipeline and the Random Forest model\n\"Pipeline\" is an API in SparkML that's used for building models.\nAdditional information on SparkML: https://spark.apache.org/docs/2.0.2/ml-guide.html",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, IndexToString\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import RandomForestClassifier\n\n# StringIndexer encodes a string column of labels to a column of label indices. \nSI1 = StringIndexer(inputCol='Gender', outputCol='GenderEncoded')\nSI2 = StringIndexer(inputCol='Status',outputCol='StatusEncoded')\nSI3 = StringIndexer(inputCol='CarOwner',outputCol='CarOwnerEncoded')\nSI4 = StringIndexer(inputCol='Paymethod',outputCol='PaymethodEncoded')\nSI5 = StringIndexer(inputCol='LocalBilltype',outputCol='LocalBilltypeEncoded')\nSI6 = StringIndexer(inputCol='LongDistanceBilltype',outputCol='LongDistanceBilltypeEncoded')\n\n# Pipelines API requires that input variables are passed in  a vector\nassembler = VectorAssembler(inputCols=[\"GenderEncoded\", \"StatusEncoded\", \"CarOwnerEncoded\", \"PaymethodEncoded\", \"LocalBilltypeEncoded\", \\\n                                       \"LongDistanceBilltypeEncoded\", \"Children\", \"EstIncome\", \"Age\", \"LongDistance\", \"International\", \"Local\",\\\n                                      \"Dropped\",\"Usage\",\"RatePlan\"], outputCol=\"features\")",
            "cell_type": "code",
            "execution_count": 6,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "# encode the label column\nlabelIndexer = StringIndexer(inputCol='CHURN', outputCol='label').fit(data)",
            "cell_type": "code",
            "execution_count": 7,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "# instantiate the algorithm, take the default settings\nrf=RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")",
            "cell_type": "code",
            "execution_count": 8,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "# Convert indexed labels back to original labels.\nlabelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)",
            "cell_type": "code",
            "execution_count": 9,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "# build the pipeline\npipeline = Pipeline(stages=[SI1,SI2,SI3,SI4,SI5,SI6, labelIndexer, assembler, rf, labelConverter])# Split data into train and test datasets",
            "cell_type": "code",
            "execution_count": 10,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "# Split data into train and test datasets\n(trainingData, testingData) = data.randomSplit([0.7, 0.3],seed=9)\ntrainingData.cache()\ntestingData.cache()",
            "cell_type": "code",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "DataFrame[ID: int, Gender: string, Status: string, Children: double, EstIncome: double, CarOwner: string, Age: double, LongDistance: double, International: double, Local: double, Dropped: double, Paymethod: string, LocalBilltype: string, LongDistanceBilltype: string, Usage: double, RatePlan: double, CHURN: string]"
                    },
                    "execution_count": 11
                }
            ],
            "metadata": {}
        },
        {
            "source": "# Build model. The fitted model from a Pipeline is a PipelineModel, which consists of fitted models and transformers, corresponding to the pipeline stages.\nmodel = pipeline.fit(trainingData)",
            "cell_type": "code",
            "execution_count": 12,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "### Step 6: Score the test data set",
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "results = model.transform(testingData)",
            "cell_type": "code",
            "execution_count": 13,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "### Step 7: Model Evaluation ",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "print 'Precision model1 = {:.2f}.'.format(results.filter(results.label == results.prediction).count() / float(results.count()))",
            "cell_type": "code",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Precision model1 = 0.92.\n"
                }
            ],
            "metadata": {}
        },
        {
            "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\nprint 'Area under ROC curve = {:.2f}.'.format(evaluator.evaluate(results))",
            "cell_type": "code",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Area under ROC curve = 0.91.\n"
                }
            ],
            "metadata": {}
        },
        {
            "source": "### Step 8: Save Model in WML repository\n\nIn this section you will store your model in the Watson Machine Learning (WML) repository by using Python client libraries.\n* <a href=\"https://console.ng.bluemix.net/docs/services/PredictiveModeling/index.html\">WML Documentation</a>\n* <a href=\"http://watson-ml-api.mybluemix.net/\">WML REST API</a> \n* <a href=\"https://watson-ml-staging-libs.mybluemix.net/repository-python/\">WML Repository API</a>\n<br/>\n\nFirst, you must import client libraries.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact",
            "cell_type": "code",
            "execution_count": 16,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "Put your authentication information from your instance of the Watson Machine Learning service in <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> in the next cell. You can find your information in the **Service Credentials** tab of your service instance in Bluemix.\n\n![WML Credentials](https://raw.githubusercontent.com/yfphoon/IntroToWML/master/images/WML%20Credentials.png)\n\n<span style=\"color:red\">Replace the service_path and credentials with your own information</span>\n\nservice_path=[your url]<br/>\ninstance_id=[your instance_id]<br/>\nusername=[your username]<br/>\npassword=[your password]<br/>",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "# @hidden_cell\nservice_path = 'https://ibm-watson-ml.mybluemix.net'\ninstance_id = '8b50daba-d9c2-4a08-98f6-66715f390201'\nusername = 'a6fbe360-c6a3-46df-99da-e889cb211564'\npassword = '576df272-5ca3-471f-8ba0-0c83f81a9951'",
            "cell_type": "code",
            "execution_count": 17,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "Authorize the repository client:",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "ml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)",
            "cell_type": "code",
            "execution_count": 18,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "Create the model artifact.\n\n<b>Tip:</b> The MLRepositoryArtifact method expects a trained model object, training data, and a model name. (It is this model name that is displayed by the Watson Machine Learning service).\n",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "model_artifact = MLRepositoryArtifact(model, training_data=trainingData, name=\"Predict Customer Churn\")",
            "cell_type": "code",
            "execution_count": 19,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "Save model artifact to your Watson Machine Learning instance:",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "saved_model = ml_repository_client.models.save(model_artifact)",
            "cell_type": "code",
            "execution_count": 20,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "# Print the saved model properties\nprint \"modelType: \" + saved_model.meta.prop(\"modelType\")\nprint \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\nprint \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\nprint \"label: \" + saved_model.meta.prop(\"label\")",
            "cell_type": "code",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "modelType: sparkml-model-2.0\ncreationTime: 2017-11-30 16:08:52.374000+00:00\nmodelVersionHref: https://ibm-watson-ml.mybluemix.net/v2/artifacts/models/0db9f87d-a0b0-42fb-9899-cc9909d71651/versions/a2aca77d-d770-49bd-a211-b1f0e948ff36\nlabel: CHURN\n"
                }
            ],
            "metadata": {}
        },
        {
            "source": "### Step 9: Generate the Authorization Token for Invoking the model",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "import urllib3, requests, json\n\nheaders = urllib3.util.make_headers(basic_auth='{}:{}'.format(username, password))\nurl = '{}/v2/identity/token'.format(service_path)\nresponse = requests.get(url, headers=headers)\nmltoken = json.loads(response.text).get('token')",
            "cell_type": "code",
            "execution_count": 22,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "print(mltoken)",
            "cell_type": "code",
            "execution_count": 23,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "eyJhbGciOiJSUzUxMiIsInR5cCI6IkpXVCJ9.eyJ0ZW5hbnRJZCI6IjhiNTBkYWJhLWQ5YzItNGEwOC05OGY2LTY2NzE1ZjM5MDIwMSIsImluc3RhbmNlSWQiOiI4YjUwZGFiYS1kOWMyLTRhMDgtOThmNi02NjcxNWYzOTAyMDEiLCJwbGFuSWQiOiIzZjZhY2Y0My1lZGU4LTQxM2EtYWM2OS1mOGFmM2JiMGNiZmUiLCJyZWdpb24iOiJ1cy1zb3V0aCIsInVzZXJJZCI6ImE2ZmJlMzYwLWM2YTMtNDZkZi05OWRhLWU4ODljYjIxMTU2NCIsImlzcyI6Imh0dHA6Ly8xMjkuNDEuMjI5LjE4ODo4MDgwL3YyL2lkZW50aXR5IiwiaWF0IjoxNTEyMDU4MTM3LCJleHAiOjE1MTIwODY5Mzd9.WAa9nVyc0SawmjbA63Vlhueu5weF_fR_06w7cebxsYJ3zHldDfJv0cS3rKfOEhsdScvkxPw1deyxYDEGvG9SoGD8oUzKy_6uy9RQ2vGB3f8sBV9s_Rmghqho4fmJAdjeNpqsBn3dcNd_5OKvRaAPJ8a1eDajW08q1g6HN2cyl4v6cphC4dmeC6P4A23Nn5UvUzKFsAjo3FwXcjnoDCDVf39TKAql3HYYuBdbFcXGwS_780laWLSswD1fkvpx-QaAs7g4dMAwROGIMs-hI-AIfnqJumLGdycXpsdikVg6DsMsE6vUzA-8TYnBoHPINhb0B25TF9pDwTrR0TmmDzrqAQ\n"
                }
            ],
            "metadata": {}
        },
        {
            "source": "### Step 10:  Go to WML in Bluemix to create a Deployment Endpoint\n\n* In your <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> dashboard, click into your WML Service and click the **Launch Dashboard** button under Watson Machine Learing.\n![WML Launch Dashboard](https://raw.githubusercontent.com/yfphoon/dsx_demo/master/WML_Launch_Dashboard.png)\n\n<br/>\n* You should see your deployed model in the **Models** tab\n",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "* Under *Actions*, click on the 3 ellipses and click ***Create Deployment***.  Give your deployment configuration a unique name, e.g. \"Predict Customer Churn Deply\", select Type=Online and click **Save**.\n<br/>\n<br/>\n* In the *Deployments tab*, under *Actions*, click **View Details**\n<br/>\n<br/>\n* Scoll down to **API Details**, copy the value of the **Scoring Endpoint** into your notepad.  (e.g. \thttps://ibm-watson-ml.mybluemix.net/v2/published_models/64fd0462-3f8a-4b42-820b-59a4da9b7dc6/deployments/7d9995ed-7daf-4cfd-b40f-37cb8ab3d88f/online)",
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "### Step 11:  Invoke the model through REST API call",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#### Create a JSON Sample record for the model ",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "sample_data = {\n    \"fields\": [\n    \"ID\",\n    \"Gender\",\n    \"Status\",\n    \"Children\",\n    \"EstIncome\",\n    \"CarOwner\",\n    \"Age\",\n    \"LongDistance\",\n    \"International\",\n    \"Local\",\n    \"Dropped\",\n    \"Paymethod\",\n    \"LocalBilltype\",\n    \"LongDistanceBilltype\",\n    \"Usage\",\n    \"RatePlan\"\n    ],\n    \"values\": [ [999,\"F\",\"M\",2.0,77551.100000,\"Y\",33.600000,20.530000,0.000000,41.890000,1.000000,\"CC\",\"Budget\",\"Standard\",62.420000,2.000000] ]\n} \n\nsample_json = json.dumps(sample_data)",
            "cell_type": "code",
            "execution_count": 24,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        },
        {
            "source": "#### Make Rest API call to test the deployed model",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "# Get the scoring endpoint from the WML service\n# Replace the value for scoring_endpoint with your own scoring endpoint\nscoring_endpoint = 'https://ibm-watson-ml.mybluemix.net/v3/wml_instances/8b50daba-d9c2-4a08-98f6-66715f390201/published_models/06a77db1-ef58-409f-a484-b5096d7944dd/deployments/535ea591-c3ce-4efb-b0cb-eee10313b59f/online'\nheader_online = {'Content-Type': 'application/json', 'Authorization': \"Bearer \" + mltoken}\n\n# API call here\nresponse_scoring = requests.post(scoring_endpoint, data=sample_json, headers=header_online)\n\nprint response_scoring.text",
            "cell_type": "code",
            "execution_count": 25,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "{\n  \"fields\": [\"ID\", \"Gender\", \"Status\", \"Children\", \"EstIncome\", \"CarOwner\", \"Age\", \"LongDistance\", \"International\", \"Local\", \"Dropped\", \"Paymethod\", \"LocalBilltype\", \"LongDistanceBilltype\", \"Usage\", \"RatePlan\", \"CHURN\", \"GenderEncoded\", \"StatusEncoded\", \"CarOwnerEncoded\", \"PaymethodEncoded\", \"LocalBilltypeEncoded\", \"LongDistanceBilltypeEncoded\", \"label\", \"features\", \"rawPrediction\", \"probability\", \"prediction\", \"predictedLabel\"],\n  \"values\": [[999, \"F\", \"M\", 2.0, 77551.1, \"Y\", 33.6, 20.53, 0.0, 41.89, 1.0, \"CC\", \"Budget\", \"Standard\", 62.42, 2.0, \"F\", 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 77551.1, 33.6, 20.53, 0.0, 41.89, 1.0, 62.42, 2.0], [18.94239534793227, 1.0576046520677282], [0.9471197673966136, 0.05288023260338642], 0.0, \"F\"]]\n}\n"
                }
            ],
            "metadata": {}
        },
        {
            "source": "#### Grab Predicted Value ",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "wml = json.loads(response_scoring.text)\n\n# First zip the fields and values together\nzipped_wml = zip(wml['fields'], wml['values'].pop())\n\n# Next iterate through items and grab the prediction value\nprint(\"Predicted Churn: \" + [v for (k,v) in zipped_wml if k == 'predictedLabel'].pop())",
            "cell_type": "code",
            "execution_count": 26,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Predicted Churn: F\n"
                }
            ],
            "metadata": {}
        },
        {
            "source": "",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {
                "collapsed": true
            }
        }
    ],
    "nbformat": 4,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1",
            "name": "python2-spark21",
            "language": "python"
        },
        "language_info": {
            "mimetype": "text/x-python",
            "nbconvert_exporter": "python",
            "version": "2.7.14",
            "name": "python",
            "pygments_lexer": "ipython2",
            "file_extension": ".py",
            "codemirror_mode": {
                "version": 2,
                "name": "ipython"
            }
        }
    }
}